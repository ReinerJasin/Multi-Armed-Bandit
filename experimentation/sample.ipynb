{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bandit:\n",
    "    def __init__(self, payoff_probs):\n",
    "        self.actions = range(len(payoff_probs))\n",
    "        self.pay_offs = payoff_probs\n",
    "\n",
    "    def sample(self, action):\n",
    "        selector = random.random()\n",
    "        # we are going to keep it simple with 1 or 0 being the only rewards\n",
    "        return 1 if selector <= self.pay_offs[action] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc034601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_explore_agent(bandit, iterations, initial_rounds = 10):\n",
    "    \"\"\"Initially explore initial_rounds times and then stick to the best action.\"\"\"\n",
    "    pay_offs = dict()\n",
    "    best_action = -1\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # for the initial rounds pick a random action\n",
    "        if i < initial_rounds:\n",
    "            a = random.choice(bandit.actions)\n",
    "            r = bandit.sample(a)\n",
    "\n",
    "            #update rewards\n",
    "            if a in pay_offs:\n",
    "                pay_offs[a].append(r)\n",
    "            else:\n",
    "                pay_offs[a] = [r]\n",
    "        # otherwise pick the best one thus far\n",
    "        else:\n",
    "            if (best_action == -1):\n",
    "                # check for the action with the best average payoff\n",
    "                mean_dict = {}\n",
    "                for key,val in pay_offs.items():\n",
    "                    mean_dict[key] = np.mean(val)\n",
    "                best_action = max(mean_dict, key=mean_dict.get)\n",
    "            a = best_action\n",
    "\n",
    "            r = bandit.sample(a)\n",
    "\n",
    "        yield a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_agent(bandit, iterations, epsilon = 0.2, initial_rounds = 1):\n",
    "    \"\"\"Use the epsilon-greedy algorithm by performing the action with the best average\n",
    "    payoff with the probability (1-epsilon), otherwise pick a random action to keep\n",
    "    exploring.\"\"\"\n",
    "\n",
    "    pay_offs = dict()\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # sometimes randomly pick an action to explore\n",
    "        if random.random() < epsilon or i < initial_rounds:\n",
    "            a = random.choice(bandit.actions)\n",
    "        # otherwise pick the best one thus far\n",
    "        else:\n",
    "            # check for the action with the best average payoff\n",
    "            new_dict = {}\n",
    "            for key,val in pay_offs.items():\n",
    "                new_dict[key] = np.mean(val)\n",
    "            a = max(new_dict, key=new_dict.get)\n",
    "\n",
    "        r = bandit.sample(a)\n",
    "\n",
    "        #update rewards\n",
    "        if a in pay_offs:\n",
    "            pay_offs[a].append(r)\n",
    "        else:\n",
    "            pay_offs[a] = [r]\n",
    "\n",
    "        yield a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5798bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_agent(bandit, iterations):\n",
    "    \"\"\"Randomly select an action and reward.\"\"\"\n",
    "\n",
    "    for i in range(iterations):\n",
    "        a = random.choice(bandit.actions)\n",
    "        r = bandit.sample(a)\n",
    "        yield a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_offs = [0.25, 0.3, 0.5, 0.1, 0.3, 0.25, 0]\n",
    "bandit = Bandit(pay_offs)\n",
    "\n",
    "# methods = [random_agent, initial_explore_agent, epsilon_greedy_agent, decaying_epsilon_greedy_agent, optimal_agent]\n",
    "f = plt.figure()\n",
    "\n",
    "methods = [initial_explore_agent, epsilon_greedy_agent]\n",
    "\n",
    "number_of_iterations = 200\n",
    "number_of_trials = 50\n",
    "\n",
    "for m in range(len(methods)):\n",
    "  method = methods[m]\n",
    "  total_rewards = []\n",
    "\n",
    "  list_of_cumulative_rewards = []\n",
    "  fan = []\n",
    "\n",
    "  for trial in range(number_of_trials):\n",
    "    total_reward = 0\n",
    "    cumulative_reward = []\n",
    "\n",
    "    for a, r in method(bandit, number_of_iterations):\n",
    "      total_reward += r\n",
    "      cumulative_reward.append(total_reward)\n",
    "\n",
    "    #Store the results\n",
    "    total_rewards.append(total_reward)\n",
    "    if trial == 0:\n",
    "      fan = pd.DataFrame(cumulative_reward, columns=['y'])\n",
    "      fan['x'] = fan.index+1\n",
    "    else:\n",
    "      fan2 = pd.DataFrame(cumulative_reward, columns=['y'])\n",
    "      fan2['x'] = fan2.index+1\n",
    "\n",
    "      fan = pd.concat([fan, fan2], ignore_index=True)\n",
    "\n",
    "    list_of_cumulative_rewards.append(cumulative_reward)\n",
    "\n",
    "  sns.lineplot(x='x', y='y', data=fan)  #default is to use bootstrap to calculate confidence interval\n",
    "\n",
    "  print(method.__name__, \":\", np.mean(total_rewards))\n",
    "\n",
    "plt.title(\"Cumulative reward for each algorithm over {} iterations with {} trials.\".format(number_of_iterations, number_of_trials))\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.legend([method.__name__ for method in methods])\n",
    "\n",
    "f.savefig(\"Iterations.pdf\", bbox_inches='tight')\n",
    "f.savefig(\"Iterations.svg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ac9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = np.random.choice(np.arange(1, 7), p=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
