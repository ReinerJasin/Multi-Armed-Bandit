{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandit with Continuous Context and Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In creating a contextual bandit agent, we have some parameters that we need to degine, which are:\n",
    "* `NUM_OF_ACTION` = number of bandit can be chosen\n",
    "* `NUM_OF_CONTEXT` = number of feature affecting the reward\n",
    "* `ALPHA` = coefficient that affects the bandit's tendency to explore (works by multiplying the confidence bound and increase its proportion compared to the expected reward)\n",
    "* `NUM_OF_TRIALS` = how many times we take action for simulation to calculate the estimate of each bandit's return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ACTION = 10\n",
    "NUM_OF_CONTEXT = 5\n",
    "\n",
    "ALPHA = 2\n",
    "\n",
    "NUM_OF_TRIALS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging for regret calculation\n",
    "\n",
    "# Best expected reward for each round\n",
    "best_expected_reward = []\n",
    "\n",
    "# Actual reward\n",
    "result_history = []\n",
    "\n",
    "# Random Exploration\n",
    "random_reward = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our LinUCB Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R_t = x_t^âŠ¤ \\theta_a + \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinUCB_Bandit:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        # True Weight (hidden from the user)\n",
    "        self.true_weight = np.random.randn(NUM_OF_CONTEXT)   # Theta_a\n",
    "\n",
    "\n",
    "        self.feature_covariance_matrix = np.identity(NUM_OF_CONTEXT) # Identity matrix with a dimension of the number of action\n",
    "        self.weighted_reward_matrix = np.zeros((NUM_OF_CONTEXT,1))\n",
    "\n",
    "        # Estimation of the true weight, should get closer to the true weight by the end of the trials\n",
    "        self.estimated_weight = np.zeros(NUM_OF_CONTEXT)\n",
    "\n",
    "        self.number_pulled = 0\n",
    "\n",
    "    def return_reward(self, context = np.random.rand(NUM_OF_CONTEXT)):\n",
    "\n",
    "        # True weight vector for a particular arm (unknown in real applications)\n",
    "        # theta_a = np.array([0.5, -0.2, 0.8, 0.3, -0.5])\n",
    "\n",
    "        # Noise (Gaussian)\n",
    "        noise = np.random.normal(0, 0.1)  \n",
    "\n",
    "        # Compute reward\n",
    "        reward = np.dot(context, self.true_weight) + noise\n",
    "\n",
    "        self.number_pulled += 1\n",
    "\n",
    "        # REGRET\n",
    "        result_history.append(reward)\n",
    "\n",
    "        return context, reward\n",
    "\n",
    "    def update_ucb_matrix(self, context, reward):\n",
    "        \n",
    "        # Resize context array\n",
    "        context_resized = np.array([context])\n",
    "\n",
    "        # Count feature covarianve matrix (A_b)\n",
    "        self.feature_covariance_matrix += np.matmul(context_resized.transpose(), context_resized)\n",
    "\n",
    "        # Count weight sum reward (b_b)\n",
    "        self.weighted_reward_matrix += reward * context_resized.transpose()\n",
    "\n",
    "        inverted_feature_cov = np.linalg.inv(self.feature_covariance_matrix)\n",
    "        self.estimated_weight = np.matmul(inverted_feature_cov, self.weighted_reward_matrix)\n",
    "\n",
    "        # return self.feature_covariance_matrix, self.weighted_reward_matrix\n",
    "    \n",
    "    def calculate_ucb_value(self, context):\n",
    "\n",
    "        # Resize context array\n",
    "        context_resized = np.array([context])\n",
    "\n",
    "        # Inverted feature covariance\n",
    "        # inverted_feature_cov = c\n",
    "\n",
    "        # Count estimated weight\n",
    "        # self.estimated_weight = np.matmul(inverted_feature_cov, self.weighted_reward_matrix)\n",
    "\n",
    "        # Expected reward of the bandit with respect to the current context\n",
    "        expected_reward = np.dot(context_resized, self.estimated_weight)\n",
    "\n",
    "        # Confidence bound\n",
    "        confidence_bound = np.sqrt(np.matmul(np.matmul(context_resized, np.linalg.inv(self.feature_covariance_matrix)), context_resized.transpose()))\n",
    "        \n",
    "        # Getting Upper confidence bound by adding the confidence bound times by alpha (multiplier)\n",
    "        upper_confidence_bound = expected_reward + (ALPHA * confidence_bound)\n",
    "\n",
    "        return context, context_resized, np.linalg.inv(self.feature_covariance_matrix), self.estimated_weight, expected_reward, confidence_bound, upper_confidence_bound \n",
    "        # return upper_confidence_bound\n",
    "        # np.linalg.inv(linUCB.feature_covariance_matrix)\n",
    "\n",
    "    def logging(context, bandit_choice, noise):\n",
    "        # Noise (Gaussian)\n",
    "        noise = np.random.normal(0, 0.1)  \n",
    "\n",
    "        # Compute reward\n",
    "        reward = np.dot(context, self.true_weight) + noise\n",
    "\n",
    "        self.number_pulled += 1\n",
    "\n",
    "        # REGRET\n",
    "        result_history.append(reward)\n",
    "\n",
    "        return context, reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linear UCB Bandit Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty list, and then loop to the number of action and append it to the list. The number of action could represent the number of product in a recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandit successfully created!\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store our bandit\n",
    "bandit_list = []\n",
    "\n",
    "# Append n amount of bandits\n",
    "for i in range(NUM_OF_ACTION):\n",
    "\n",
    "    bandit_list.append(LinUCB_Bandit())\n",
    "\n",
    "# Check whether the bandit class is created correctly\n",
    "if len(bandit_list) == NUM_OF_ACTION:\n",
    "    print('Bandit successfully created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug (Check details of the created bandit, this shouldn't be run in real scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36484893 -0.35093028 -1.33302671  0.74494551  0.45361073]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[-0.18925154 -1.3298439  -0.79831899  1.35906858 -0.4382645 ]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[-0.03380492  0.07136319 -1.85953795  0.88013191 -1.07628729]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[ 1.63402143  0.08696553  0.13650421 -0.5799358  -0.05185159]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[-1.05727349  0.95323234 -0.85610838 -1.69826187  0.07903731]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[-0.78067437 -1.64404716  1.11199186 -0.93517228 -0.51306536]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[ 1.2171579   0.80528354 -0.07060563  0.46193635  1.8706972 ]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[ 0.63687475 -0.55820471  0.19267513  0.497489   -0.0332494 ]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[ 0.6462296  -0.32903263  0.05590383 -1.33102677  0.70189086]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[-0.6810165   1.3650234   0.0556303  -1.32294232  0.33049451]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "for bandit in bandit_list:\n",
    "    # DEBUG\n",
    "    print(bandit.true_weight)\n",
    "    print(bandit.feature_covariance_matrix)\n",
    "    print(bandit.weighted_reward_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Contextual Bandit iteration for estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a context randomly to specify current context. In real scenario, each index from the context array supposed to represent a feature from a recommendation (age, gender, income, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated context: [ 0.52750417 -1.44516739 -0.12291913 -0.81016292 -0.28087726]\n"
     ]
    }
   ],
   "source": [
    "context = np.random.randn(NUM_OF_CONTEXT)\n",
    "\n",
    "# For Hardcode (adjust with the number of context)\n",
    "# context = [0.5, 1.2]\n",
    "\n",
    "print(f'Generated context: {context}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate UCB Value for each action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the context, we are going to count the UCB_Value for each bandit. UCB value will balance between exploration and exploitation.\n",
    "\n",
    "We start off by creating an empty array to store all calculated UCB. Then, we loop through all the bandits for the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_ucb_value = []\n",
    "\n",
    "for bandit in bandit_list:\n",
    "        \n",
    "    context, context_resized, inverted_feature_cov, estimated_weight, expected_reward, confidence_bound, upper_confidence_bound  = bandit.calculate_ucb_value(context=context)\n",
    "\n",
    "    # print(context)\n",
    "    # print(context_resized)\n",
    "    # print(inverted_feature_cov)\n",
    "    # print(estimated_weight)\n",
    "    # print(expected_reward)\n",
    "    # print(confidence_bound)\n",
    "    # print(upper_confidence_abound)\n",
    "\n",
    "    bandit_ucb_value.append(upper_confidence_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Pick the best UCB and Pull the arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the UCB value and extract the index of the best UCB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]]), array([[3.53108172]])]\n",
      "Index of bandit with the highest UCB is 0\n"
     ]
    }
   ],
   "source": [
    "print(bandit_ucb_value)\n",
    "\n",
    "bandit_best_ucb = np.argmax(bandit_ucb_value)\n",
    "print(f'Index of bandit with the highest UCB is {bandit_best_ucb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first iteration, we don't have any knowledge about the environment, so we will have the same UCB value for each bandit. Meaning if we take the highest UCB, we'll immediately get the first index which is '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earned Reward: -0.3220181046061935\n"
     ]
    }
   ],
   "source": [
    "context, reward = bandit_list[bandit_best_ucb].return_reward(context)\n",
    "print(f'Earned Reward: {reward}')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Update UCB to renew the knowledge and estimated weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_list[bandit_best_ucb].update_ucb_matrix(context, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bandit 0 estimated weight:\n",
      "[[-0.04125828]\n",
      " [ 0.11303251]\n",
      " [ 0.00961401]\n",
      " [ 0.06336619]\n",
      " [ 0.02196857]]\n",
      "\n",
      "Bandit 1 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 2 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 3 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 4 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 5 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 6 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 7 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 8 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n",
      "Bandit 9 estimated weight:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, bandit in enumerate(bandit_list):\n",
    "    print(f'Bandit {i} estimated weight:')\n",
    "    print(bandit.estimated_weight)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the bandit 0 estimated weight is now updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish simulating for 9999 iterations!\n"
     ]
    }
   ],
   "source": [
    "# Repeat with number of trials\n",
    "for i in range(NUM_OF_TRIALS-1):    # -1 for our recent example trials\n",
    "\n",
    "    # Step 1: Preparation\n",
    "    context = np.random.randn(NUM_OF_CONTEXT)\n",
    "    # print(f'Generated context: {context}')\n",
    "\n",
    "    # Step 2: Calculate UCB Value of each arm\n",
    "    bandit_ucb_value = []\n",
    "\n",
    "    for bandit in bandit_list:\n",
    "        \n",
    "        context, context_resized, inverted_feature_cov, estimated_weight, expected_reward, confidence_bound, upper_confidence_bound  = bandit.calculate_ucb_value(context=context)\n",
    "\n",
    "        bandit_ucb_value.append(upper_confidence_bound)\n",
    "\n",
    "    # Step 3: Take the highest UCB value and pull the arm\n",
    "    bandit_best_ucb = np.argmax(bandit_ucb_value)\n",
    "    # print(f'Bandit index to pull: {bandit_best_ucb}')\n",
    "\n",
    "    context, reward = bandit_list[bandit_best_ucb].return_reward(context)\n",
    "    # print(f'Earned Reward: {reward}')\n",
    "    # print()\n",
    "\n",
    "    # Step 4: Update the UCB Matrix of the pulled arm\n",
    "    bandit_list[bandit_best_ucb].update_ucb_matrix(context, reward)\n",
    "\n",
    "    # Ignored Step\n",
    "    logging(context, bandit_choice=np.random.randint(0,10), )\n",
    "\n",
    "# Output\n",
    "print(f'finish simulating for {NUM_OF_TRIALS-1} iterations!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on the True weight and estimated weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resized: [[ 2.55686698 -1.16240465 -0.75582164  0.22185639  1.34489915]]\n",
      "============ Bandit-0 ============== number of pull: 743\n",
      "True weight: [-0.36484893 -0.35093028 -1.33302671  0.74494551  0.45361073]\n",
      "Estimated weight: [[-0.36265786]\n",
      " [-0.36050419]\n",
      " [-1.32805709]\n",
      " [ 0.75319867]\n",
      " [ 0.45635988]]\n",
      "Expected Reward: [[1.27641808]]\n",
      "\n",
      "============ Bandit-1 ============== number of pull: 2203\n",
      "True weight: [-0.18925154 -1.3298439  -0.79831899  1.35906858 -0.4382645 ]\n",
      "Estimated weight: [[-0.19073239]\n",
      " [-1.32689828]\n",
      " [-0.79559915]\n",
      " [ 1.35691109]\n",
      " [-0.43864687]]\n",
      "Expected Reward: [[1.36715001]]\n",
      "\n",
      "============ Bandit-2 ============== number of pull: 2823\n",
      "True weight: [-0.03380492  0.07136319 -1.85953795  0.88013191 -1.07628729]\n",
      "Estimated weight: [[-0.03348485]\n",
      " [ 0.07144198]\n",
      " [-1.86073158]\n",
      " [ 0.87854324]\n",
      " [-1.07558632]]\n",
      "Expected Reward: [[-0.01392431]]\n",
      "\n",
      "============ Bandit-3 ============== number of pull: 1669\n",
      "True weight: [ 1.63402143  0.08696553  0.13650421 -0.5799358  -0.05185159]\n",
      "Estimated weight: [[ 1.63144037]\n",
      " [ 0.08946864]\n",
      " [ 0.13327225]\n",
      " [-0.57974852]\n",
      " [-0.05993312]]\n",
      "Expected Reward: [[3.75742228]]\n",
      "\n",
      "============ Bandit-4 ============== number of pull: 2463\n",
      "True weight: [-1.05727349  0.95323234 -0.85610838 -1.69826187  0.07903731]\n",
      "Estimated weight: [[-1.05949921]\n",
      " [ 0.94957698]\n",
      " [-0.85808157]\n",
      " [-1.69524533]\n",
      " [ 0.07577853]]\n",
      "Expected Reward: [[-3.43842116]]\n",
      "\n",
      "============ Bandit-5 ============== number of pull: 3791\n",
      "True weight: [-0.78067437 -1.64404716  1.11199186 -0.93517228 -0.51306536]\n",
      "Estimated weight: [[-0.78094395]\n",
      " [-1.64160162]\n",
      " [ 1.11235059]\n",
      " [-0.935527  ]\n",
      " [-0.51300587]]\n",
      "Expected Reward: [[-1.82679689]]\n",
      "\n",
      "============ Bandit-6 ============== number of pull: 3495\n",
      "True weight: [ 1.2171579   0.80528354 -0.07060563  0.46193635  1.8706972 ]\n",
      "Estimated weight: [[ 1.2151302 ]\n",
      " [ 0.80443583]\n",
      " [-0.07359414]\n",
      " [ 0.46187171]\n",
      " [ 1.87226611]]\n",
      "Expected Reward: [[4.84794867]]\n",
      "\n",
      "============ Bandit-7 ============== number of pull: 273\n",
      "True weight: [ 0.63687475 -0.55820471  0.19267513  0.497489   -0.0332494 ]\n",
      "Estimated weight: [[ 0.62757851]\n",
      " [-0.55781317]\n",
      " [ 0.19788376]\n",
      " [ 0.49409608]\n",
      " [-0.03523799]]\n",
      "Expected Reward: [[2.1657014]]\n",
      "\n",
      "============ Bandit-8 ============== number of pull: 832\n",
      "True weight: [ 0.6462296  -0.32903263  0.05590383 -1.33102677  0.70189086]\n",
      "Estimated weight: [[ 0.65304269]\n",
      " [-0.33556678]\n",
      " [ 0.0641101 ]\n",
      " [-1.32343022]\n",
      " [ 0.70717576]]\n",
      "Expected Reward: [[2.6688205]]\n",
      "\n",
      "============ Bandit-9 ============== number of pull: 1707\n",
      "True weight: [-0.6810165   1.3650234   0.0556303  -1.32294232  0.33049451]\n",
      "Estimated weight: [[-0.67941897]\n",
      " [ 1.36170747]\n",
      " [ 0.05664564]\n",
      " [-1.32235307]\n",
      " [ 0.3352028 ]]\n",
      "Expected Reward: [[-3.20541156]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the result after multiple iterations\n",
    "# print(f'context: {context}')\n",
    "print(f'resized: {context_resized}')\n",
    "\n",
    "for i, bandit in enumerate(bandit_list):\n",
    "    context, context_resized, inverted_feature_cov, estimated_weight, expected_reward, confidence_bound, upper_confidence_bound  = bandit.calculate_ucb_value(context=context)\n",
    "    print(f'============ Bandit-{i} ============== number of pull: {bandit.number_pulled}')\n",
    "    # print(f'Inverted Feature Cov (Ab): {inverted_feature_cov}')\n",
    "    print(f'True weight: {bandit.true_weight}')\n",
    "    print(f'Estimated weight: {estimated_weight}')\n",
    "    print(f'Expected Reward: {expected_reward}')\n",
    "    # print(f'Confidence Bound: {confidence_bound}')\n",
    "    # print(f'UCB Value: {upper_confidence_bound}')\n",
    "    print()\n",
    "    # print(f'feature Cov Matrix: {bandit.feature_covariance_matrix}')\n",
    "    # print(f'weighted_reward: {bandit.weighted_reward_matrix}')\n",
    "    # print(f'estimated weight: {bandit.estimated_weight}')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true weight and the estimated rewards are very closed meaning that our estimation is working!\n",
    "\n",
    "We can also calculate the expected reward based on current context!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from ChatGPT:\n",
    "1. Check whether the self.feature_covariance_matrix update is correct\n",
    "\n",
    "Instead of using np.matmul like this\n",
    "`self.feature_covariance_matrix += np.matmul(context_resized.transpose(), context_resized)`\n",
    "\n",
    "Use this\n",
    "`self.feature_covariance_matrix += np.outer(context, context)`\n",
    "\n",
    "2. Fix UCB Calculation\n",
    "from:\n",
    "`confidence_bound = np.sqrt(np.matmul(np.matmul(context_resized, inverted_feature_cov), context_resized.transpose()))`\n",
    "\n",
    "to:\n",
    "`confidence_bound = np.sqrt(np.dot(context, np.dot(inverted_feature_cov, context)))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The suggestion from ChatGPT might be wrong, since the code I created is able to estimate the context true weight quite close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_reward(self, context = np.random.rand(NUM_OF_CONTEXT)):\n",
    "\n",
    "        # True weight vector for a particular arm (unknown in real applications)\n",
    "        # theta_a = np.array([0.5, -0.2, 0.8, 0.3, -0.5])\n",
    "\n",
    "        # Noise (Gaussian)\n",
    "        noise = np.random.normal(0, 0.1)  \n",
    "\n",
    "        # Compute reward\n",
    "        reward = np.dot(context, self.true_weight) + noise\n",
    "\n",
    "\n",
    "        # REGRET\n",
    "        result_history.append(reward)\n",
    "\n",
    "        return context, reward\n",
    "\n",
    "# Random exploration for metric purposes\n",
    "for i in range(NUM_OF_TRIALS):\n",
    "    random_index = np.random.randint(0,10)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinUCB Result\n",
    "y1 = np.cumsum(result_history)\n",
    "\n",
    "# Best possible reward\n",
    "best_mean = np.argmax([bandit.mean for bandit in list_bandit])\n",
    "y2 = [i*best_mean for i in range(0,current_round-1)]\n",
    "\n",
    "# Simulated 100% Explore\n",
    "y3 = np.cumsum(explore_results)\n",
    "\n",
    "# Generate x values\n",
    "x = range(len(y1))\n",
    "\n",
    "# Plot the lines\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(x, y1, label='Earned Reward', color='green', alpha=0.7)\n",
    "plt.plot(x, y2, label='Maximum expected reward', color='grey', alpha=0.7)\n",
    "plt.plot(x, y3, label='Random Explore', color='purple', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Number of trials')\n",
    "plt.ylabel('Rewards')\n",
    "plt.title('Upper Confidence Bound 1 - Algorithm Performance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden code (useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated context: [0.5, 1.2]\n",
      "Earned: -0.31201530096925756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.25, 0.6 ],\n",
       "        [0.6 , 2.44]]),\n",
       " array([[-0.15600765],\n",
       "        [-0.37441836]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the arm\n",
    "context, reward = bandit_list[bandit_best_ucb].return_reward(context)\n",
    "print(f'Generated context: {context}')\n",
    "print(f'Earned: {reward}')\n",
    "\n",
    "# Update the UCB Matrix of the pulled arm\n",
    "bandit_list[bandit_best_ucb].update_ucb_matrix(context, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.25 0.6 ]\n",
      " [0.6  2.44]]\n",
      "[[-0.15600765]\n",
      " [-0.37441836]]\n"
     ]
    }
   ],
   "source": [
    "print(bandit_list[0].feature_covariance_matrix)\n",
    "print(bandit_list[0].weighted_reward_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: [1.59441619 0.43739919]\n",
      "resized: [[1.59441619 0.43739919]]\n",
      "============ Bandit-0 ============== number of pull: 3232\n",
      "Inverted Feature Cov (Ab): [[2.18040897e-04 4.76941667e-05]\n",
      " [4.76941667e-05 5.51056539e-04]]\n",
      "True weight: [-1.42916069  0.52952878]\n",
      "Estimated weight: [[-1.42837013]\n",
      " [ 0.52861006]]\n",
      "Expected Reward: [[-2.04620285]]\n",
      "Confidence Bound: [[0.02694895]]\n",
      "UCB Value: [[-1.99230495]]\n",
      "\n",
      "============ Bandit-1 ============== number of pull: 8\n",
      "Inverted Feature Cov (Ab): [[ 0.27158334 -0.09528139]\n",
      " [-0.09528139  0.14801412]]\n",
      "True weight: [ 0.3577058  -0.04912457]\n",
      "Estimated weight: [[0.22776101]\n",
      " [0.06170951]]\n",
      "Expected Reward: [[0.39013754]]\n",
      "Confidence Bound: [[0.76539474]]\n",
      "UCB Value: [[1.92092702]]\n",
      "\n",
      "============ Bandit-2 ============== number of pull: 5\n",
      "Inverted Feature Cov (Ab): [[ 0.37793991 -0.11087077]\n",
      " [-0.11087077  0.18691238]]\n",
      "True weight: [0.99212952 0.03608986]\n",
      "Estimated weight: [[0.5557568 ]\n",
      " [0.10314583]]\n",
      "Expected Reward: [[0.93122354]]\n",
      "Confidence Bound: [[0.91755263]]\n",
      "UCB Value: [[2.76632879]]\n",
      "\n",
      "============ Bandit-3 ============== number of pull: 489\n",
      "Inverted Feature Cov (Ab): [[0.00191356 0.00878636]\n",
      " [0.00878636 0.0951716 ]]\n",
      "True weight: [ 1.76727543 -0.35764693]\n",
      "Estimated weight: [[ 1.76095013]\n",
      " [-0.35999196]]\n",
      "Expected Reward: [[2.65022721]]\n",
      "Confidence Bound: [[0.18795683]]\n",
      "UCB Value: [[3.02614087]]\n",
      "\n",
      "============ Bandit-4 ============== number of pull: 2968\n",
      "Inverted Feature Cov (Ab): [[0.00063853 0.00020962]\n",
      " [0.00020962 0.00031768]]\n",
      "True weight: [ 1.55578274 -1.46817446]\n",
      "Estimated weight: [[ 1.5547493 ]\n",
      " [-1.47092595]]\n",
      "Expected Reward: [[1.83553564]]\n",
      "Confidence Bound: [[0.04445688]]\n",
      "UCB Value: [[1.92444939]]\n",
      "\n",
      "============ Bandit-5 ============== number of pull: 28\n",
      "Inverted Feature Cov (Ab): [[0.27178008 0.02881265]\n",
      " [0.02881265 0.01822936]]\n",
      "True weight: [0.377076   0.93332795]\n",
      "Estimated weight: [[0.24244329]\n",
      " [0.89703087]]\n",
      "Expected Reward: [[0.77891608]]\n",
      "Confidence Bound: [[0.85707909]]\n",
      "UCB Value: [[2.49307425]]\n",
      "\n",
      "============ Bandit-6 ============== number of pull: 4\n",
      "Inverted Feature Cov (Ab): [[ 0.21512476 -0.00361825]\n",
      " [-0.00361825  0.15023773]]\n",
      "True weight: [0.77330655 0.0545646 ]\n",
      "Estimated weight: [[0.50472829]\n",
      " [0.05760599]]\n",
      "Expected Reward: [[0.82994377]]\n",
      "Confidence Bound: [[0.75536658]]\n",
      "UCB Value: [[2.34067694]]\n",
      "\n",
      "============ Bandit-7 ============== number of pull: 260\n",
      "Inverted Feature Cov (Ab): [[ 0.210514   -0.13334284]\n",
      " [-0.13334284  0.08720365]]\n",
      "True weight: [ 0.67962357 -0.92993962]\n",
      "Estimated weight: [[ 0.46149711]\n",
      " [-0.79766687]]\n",
      "Expected Reward: [[0.38691961]]\n",
      "Confidence Bound: [[0.60486272]]\n",
      "UCB Value: [[1.59664505]]\n",
      "\n",
      "============ Bandit-8 ============== number of pull: 12380\n",
      "Inverted Feature Cov (Ab): [[ 0.00070778 -0.00031692]\n",
      " [-0.00031692  0.00020083]]\n",
      "True weight: [1.74158209 1.20372527]\n",
      "Estimated weight: [[1.74087819]\n",
      " [1.20449693]]\n",
      "Expected Reward: [[3.30253037]]\n",
      "Confidence Bound: [[0.03735883]]\n",
      "UCB Value: [[3.37724803]]\n",
      "\n",
      "============ Bandit-9 ============== number of pull: 627\n",
      "Inverted Feature Cov (Ab): [[0.04420189 0.01078489]\n",
      " [0.01078489 0.00351399]]\n",
      "True weight: [-0.2520935   1.01738456]\n",
      "Estimated weight: [[-0.23341668]\n",
      " [ 1.02202016]]\n",
      "Expected Reward: [[0.07486746]]\n",
      "Confidence Bound: [[0.35788738]]\n",
      "UCB Value: [[0.79064222]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUGGG\n",
    "print(f'context: {context}')\n",
    "print(f'resized: {context_resized}')\n",
    "\n",
    "for i, bandit in enumerate(bandit_list):\n",
    "    context, context_resized, inverted_feature_cov, estimated_weight, expected_reward, confidence_bound, upper_confidence_bound  = bandit.calculate_ucb_value(context=context)\n",
    "    print(f'============ Bandit-{i} ============== number of pull: {bandit.number_pulled}')\n",
    "    print(f'Inverted Feature Cov (Ab): {inverted_feature_cov}')\n",
    "    print(f'True weight: {bandit.true_weight}')\n",
    "    print(f'Estimated weight: {estimated_weight}')\n",
    "    print(f'Expected Reward: {expected_reward}')\n",
    "    print(f'Confidence Bound: {confidence_bound}')\n",
    "    print(f'UCB Value: {upper_confidence_bound}')\n",
    "    print()\n",
    "    # print(f'feature Cov Matrix: {bandit.feature_covariance_matrix}')\n",
    "    # print(f'weighted_reward: {bandit.weighted_reward_matrix}')\n",
    "    # print(f'estimated weight: {bandit.estimated_weight}')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'update_ucb_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# DEBUG\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mlinUCB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_ucb_matrix\u001b[49m(context=[\u001b[32m0.5\u001b[39m,\u001b[32m1.2\u001b[39m], reward=[\u001b[32m1\u001b[39m])\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'update_ucb_matrix'"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "linUCB.update_ucb_matrix(context=[0.5,1.2], reward=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [0.93135123 0.51710428]\n",
      "Reward: -0.17244695800782972\n"
     ]
    }
   ],
   "source": [
    "# Pull an arm\n",
    "context,reward = linUCB.return_reward()\n",
    "print(f'Context: {context}')\n",
    "print(f'Reward: {reward}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Update feature covariance and weight reward matrix\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m linUCB.update_ucb_matrix(context=context, reward=\u001b[43mreward\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'reward' is not defined"
     ]
    }
   ],
   "source": [
    "# Update feature covariance and weight reward matrix\n",
    "linUCB.update_ucb_matrix(context=context, reward=reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.2]\n",
      "[[1.  1.2]]\n",
      "[[ 0.9070632  -0.22304833]\n",
      " [-0.22304833  0.46468401]]\n",
      "[[0.18587361]\n",
      " [0.44609665]]\n",
      "[[0.72118959]]\n",
      "[[1.02024124]]\n",
      "[[2.76167208]]\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "context, context_resized, inverted_feature_cov, estimated_weight, expected_reward, confidence_bound, upper_confidence_bound  = linUCB.calculate_ucb_value(context=[1.0, 1.2])\n",
    "print(context)\n",
    "print(context_resized)\n",
    "print(inverted_feature_cov)\n",
    "print(estimated_weight)\n",
    "print(expected_reward)\n",
    "print(confidence_bound)\n",
    "print(upper_confidence_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  1.2]]\n",
      "[[1. ]\n",
      " [1.2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.  , 1.2 ],\n",
       "       [1.2 , 1.44]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "print(np.array([context]))\n",
    "print(np.array([context]).transpose())\n",
    "\n",
    "np.matmul(np.array([context]).transpose(), np.array([context]))\n",
    "# print(np.array(np.newaxis, context).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linUCB.feature_covariance_matrix = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MAB it's\n",
    "action_list = [] # Filled with the estimated reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Contextual Bandit we're gonna have\n",
    "# NxM matrix\n",
    "# N = Number of context or the feature\n",
    "# M = Number of actions can be taken (bandit)\n",
    "action = np.array([[], []], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {'name': ['product A', 'product B', 'product C', 'product D'],\n",
    "                'gender': pd.Series(['Male', 'Female', 'Male'], index=[0, 2, 3]),\n",
    "                'location': pd.Series(['South', 'North', 'West', 'East'], index=[0, 1, 2, 3]),\n",
    "               }\n",
    "\n",
    "data = pd.DataFrame(data=sample_data, index=[0, 1, 2, 3])\n",
    "\n",
    "# From\n",
    "#         name\t gender\t location\n",
    "# 0\t product A     Male\t    South\n",
    "# 1  product B\t    NaN\t    North\n",
    "# 2\t product C\t Female\t     West\n",
    "# 3\t product D\t   Male\t     East\n",
    "\n",
    "# To\n",
    "#    Gender_Male  Gender_Female  Location_South  Location_North  Location_West  Location_East\n",
    "# 0            1              0               1               0              0              0\n",
    "# 1            0              0               0               1              0              0\n",
    "# 2            0              1               0               0              1              0\n",
    "# 3            1              0               0               0              0              1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product A</td>\n",
       "      <td>Male</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product C</td>\n",
       "      <td>Female</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product D</td>\n",
       "      <td>Male</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  gender location\n",
       "0  product A    Male    South\n",
       "1  product B     NaN    North\n",
       "2  product C  Female     West\n",
       "3  product D    Male     East"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the data\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "encoded_data = encoder.fit_transform(data[['gender', 'location']])\n",
    "encoded_columns = encoder.get_feature_names_out(['gender', 'location'])\n",
    "\n",
    "one_hot_data = pd.DataFrame(encoded_data, columns=encoded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_nan</th>\n",
       "      <th>location_East</th>\n",
       "      <th>location_North</th>\n",
       "      <th>location_South</th>\n",
       "      <th>location_West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_Female  gender_Male  gender_nan  location_East  location_North  \\\n",
       "0            0.0          1.0         0.0            0.0             0.0   \n",
       "1            0.0          0.0         1.0            0.0             1.0   \n",
       "2            1.0          0.0         0.0            0.0             0.0   \n",
       "3            0.0          1.0         0.0            1.0             0.0   \n",
       "\n",
       "   location_South  location_West  \n",
       "0             1.0            0.0  \n",
       "1             0.0            0.0  \n",
       "2             0.0            1.0  \n",
       "3             0.0            0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class contextual_bandits:\n",
    "    def __init__(self, states, actions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m         ohe[index][states[index]] = \u001b[32m1\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ohe\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mohe_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mohe_generator\u001b[39m\u001b[34m(states, total_states)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mohe_generator\u001b[39m(states,total_states):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     ohe = np.zeros((\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m,total_states))\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index, array \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ohe):\n\u001b[32m      4\u001b[39m         ohe[index][states[index]] = \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "data = [['tom', 10], ['nick', 15], ['juli', 14]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "Index(['name', 'gender', 'location'], dtype='object')\n",
      "['Male' nan 'Female']\n",
      "02\n",
      "12\n",
      "22\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "print(data[\"gender\"].unique())\n",
    "\n",
    "# Loop through the number of entry in the data\n",
    "for i in range(data.shape[0]):\n",
    "    print(f\"{i}2\")\n",
    "\n",
    "def one_hot_encode():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_cov = np.array([[0.0, 0.0],[0.0, 0.0]])\n",
    "B_cov = np.array([[0.0, 0.0], [0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = [0.5, 1.2]\n",
    "# context = np.array([[0.5, 1.2]])\n",
    "context = np.random.randn(2)\n",
    "\n",
    "A_cov += np.matmul(context.transpose(), context)\n",
    "B_cov += np.outer(context, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69287448 0.69287448]\n",
      " [0.69287448 0.69287448]]\n",
      "[[0.06309534 0.19933923]\n",
      " [0.19933923 0.62977914]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(A_cov)\n",
    "print(B_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
